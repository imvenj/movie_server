#!/usr/bin/env python3

import sys
import cloudscraper

address = sys.argv[1]
outputExists = len(sys.argv) == 3
path = sys.argv[2] if outputExists else '/tmp/cfdl_page_content'

scraper = cloudscraper.create_scraper()

r = scraper.get(address, stream=True)
flag = 'w' if outputExists else 'wb'

with open(path, flag) as fd:
    for chunk in r.iter_content(chunk_size=128):
        fd.write(chunk)

if not outputExists:
    print(open(path).read())
